{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the Python Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the necessary Python packages found in requirements.txt and import the necessary Python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-27 02:13:51.963533: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "!pip3 install -r requirements.txt\n",
    "\n",
    "from keras.layers import Dense, Activation, Dropout, LSTM\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pyspark.sql.types import (\n",
    "    DateType,\n",
    "    DoubleType,\n",
    "    IntegerType,\n",
    "    LongType,\n",
    "    StructType,\n",
    "    StructField,\n",
    "    StringType,\n",
    "    TimestampType,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the Python notebook environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stock symbol\n",
    "STOCK_SYMBOL_UPPER = \"TSLA\"  # AA, AAPL, AMZN, MSFT, TSLA, JPM, LLY\n",
    "STOCK_SYMBOL_LOWER = \"tsla\"  # aa, aapl, amzn, msft, tsla, jpm, lly\n",
    "\n",
    "# File names\n",
    "FILE_NAME_COMBINED = f\"{STOCK_SYMBOL_LOWER}.csv\"\n",
    "\n",
    "# File paths\n",
    "FILE_PATH_COMBINED = f\"stock_combined/{FILE_NAME_COMBINED}\"\n",
    "\n",
    "# Define the schema\n",
    "COMBINED_SCHEMA = StructType(\n",
    "    [\n",
    "        StructField(\"Date\", DateType(), True),\n",
    "        StructField(\"Open\", DoubleType(), True),\n",
    "        StructField(\"High\", DoubleType(), True),\n",
    "        StructField(\"Low\", DoubleType(), True),\n",
    "        StructField(\"Close\", DoubleType(), True),\n",
    "        StructField(\"Adj_close\", DoubleType(), True),\n",
    "        StructField(\"Volume\", LongType(), True),\n",
    "        StructField(\"Normalized_sentiment\", DoubleType(), True),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#2\n",
      "flag_pred: True, sentiment_type: sentiment, data_filename: aa.csv\n",
      "[Model] Loading model from file saved_models/LSTM_sentiment_5.keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (13214, 49, 3)\n",
      "Y: (13214, 1)\n",
      "-----Predicting-----\n",
      "test data:\n",
      "X: (2291, 49, 3)\n",
      "Y: (2291, 1)\n",
      "Data saved to test_result_5/aa_sentiment_2024102709/aa_sentiment_2024102709_predicted_data.csv\n",
      "\n",
      "Results saved to test_result_5/aa_sentiment_2024102709/aa_sentiment_2024102709_eval.csv\n",
      "#2\n",
      "flag_pred: True, sentiment_type: sentiment, data_filename: aapl.csv\n",
      "[Model] Loading model from file saved_models/LSTM_sentiment_5.keras\n",
      "X: (9174, 49, 3)\n",
      "Y: (9174, 1)\n",
      "-----Predicting-----\n",
      "test data:\n",
      "X: (1578, 49, 3)\n",
      "Y: (1578, 1)\n",
      "Data saved to test_result_5/aapl_sentiment_2024102709/aapl_sentiment_2024102709_predicted_data.csv\n",
      "\n",
      "Results saved to test_result_5/aapl_sentiment_2024102709/aapl_sentiment_2024102709_eval.csv\n",
      "#2\n",
      "flag_pred: True, sentiment_type: sentiment, data_filename: amzn.csv\n",
      "[Model] Loading model from file saved_models/LSTM_sentiment_5.keras\n",
      "X: (5645, 49, 3)\n",
      "Y: (5645, 1)\n",
      "-----Predicting-----\n",
      "test data:\n",
      "X: (955, 49, 3)\n",
      "Y: (955, 1)\n",
      "Data saved to test_result_5/amzn_sentiment_2024102709/amzn_sentiment_2024102709_predicted_data.csv\n",
      "\n",
      "Results saved to test_result_5/amzn_sentiment_2024102709/amzn_sentiment_2024102709_eval.csv\n",
      "#2\n",
      "flag_pred: True, sentiment_type: sentiment, data_filename: msft.csv\n",
      "[Model] Loading model from file saved_models/LSTM_sentiment_5.keras\n",
      "X: (8047, 49, 3)\n",
      "Y: (8047, 1)\n",
      "-----Predicting-----\n",
      "test data:\n",
      "X: (1379, 49, 3)\n",
      "Y: (1379, 1)\n",
      "Data saved to test_result_5/msft_sentiment_2024102709/msft_sentiment_2024102709_predicted_data.csv\n",
      "\n",
      "Results saved to test_result_5/msft_sentiment_2024102709/msft_sentiment_2024102709_eval.csv\n",
      "#2\n",
      "flag_pred: True, sentiment_type: sentiment, data_filename: tsla.csv\n",
      "[Model] Loading model from file saved_models/LSTM_sentiment_5.keras\n",
      "X: (2839, 49, 3)\n",
      "Y: (2839, 1)\n",
      "-----Predicting-----\n",
      "test data:\n",
      "X: (460, 49, 3)\n",
      "Y: (460, 1)\n",
      "Data saved to test_result_5/tsla_sentiment_2024102709/tsla_sentiment_2024102709_predicted_data.csv\n",
      "\n",
      "Results saved to test_result_5/tsla_sentiment_2024102709/tsla_sentiment_2024102709_eval.csv\n",
      "#2\n",
      "flag_pred: True, sentiment_type: non-sentiment, data_filename: aa.csv\n",
      "[Model] Loading model from file saved_models/LSTM_non-sentiment_5.keras\n",
      "X: (13214, 49, 2)\n",
      "Y: (13214, 1)\n",
      "-----Predicting-----\n",
      "test data:\n",
      "X: (2291, 49, 2)\n",
      "Y: (2291, 1)\n",
      "Data saved to test_result_5/aa_non-sentiment_2024102709/aa_non-sentiment_2024102709_predicted_data.csv\n",
      "\n",
      "Results saved to test_result_5/aa_non-sentiment_2024102709/aa_non-sentiment_2024102709_eval.csv\n",
      "#2\n",
      "flag_pred: True, sentiment_type: non-sentiment, data_filename: aapl.csv\n",
      "[Model] Loading model from file saved_models/LSTM_non-sentiment_5.keras\n",
      "X: (9174, 49, 2)\n",
      "Y: (9174, 1)\n",
      "-----Predicting-----\n",
      "test data:\n",
      "X: (1578, 49, 2)\n",
      "Y: (1578, 1)\n",
      "Data saved to test_result_5/aapl_non-sentiment_2024102709/aapl_non-sentiment_2024102709_predicted_data.csv\n",
      "\n",
      "Results saved to test_result_5/aapl_non-sentiment_2024102709/aapl_non-sentiment_2024102709_eval.csv\n",
      "#2\n",
      "flag_pred: True, sentiment_type: non-sentiment, data_filename: amzn.csv\n",
      "[Model] Loading model from file saved_models/LSTM_non-sentiment_5.keras\n",
      "X: (5645, 49, 2)\n",
      "Y: (5645, 1)\n",
      "-----Predicting-----\n",
      "test data:\n",
      "X: (955, 49, 2)\n",
      "Y: (955, 1)\n",
      "Data saved to test_result_5/amzn_non-sentiment_2024102709/amzn_non-sentiment_2024102709_predicted_data.csv\n",
      "\n",
      "Results saved to test_result_5/amzn_non-sentiment_2024102709/amzn_non-sentiment_2024102709_eval.csv\n",
      "#2\n",
      "flag_pred: True, sentiment_type: non-sentiment, data_filename: msft.csv\n",
      "[Model] Loading model from file saved_models/LSTM_non-sentiment_5.keras\n",
      "X: (8047, 49, 2)\n",
      "Y: (8047, 1)\n",
      "-----Predicting-----\n",
      "test data:\n",
      "X: (1379, 49, 2)\n",
      "Y: (1379, 1)\n",
      "Data saved to test_result_5/msft_non-sentiment_2024102709/msft_non-sentiment_2024102709_predicted_data.csv\n",
      "\n",
      "Results saved to test_result_5/msft_non-sentiment_2024102709/msft_non-sentiment_2024102709_eval.csv\n",
      "#2\n",
      "flag_pred: True, sentiment_type: non-sentiment, data_filename: tsla.csv\n",
      "[Model] Loading model from file saved_models/LSTM_non-sentiment_5.keras\n",
      "X: (2839, 49, 2)\n",
      "Y: (2839, 1)\n",
      "-----Predicting-----\n",
      "test data:\n",
      "X: (460, 49, 2)\n",
      "Y: (460, 1)\n",
      "Data saved to test_result_5/tsla_non-sentiment_2024102709/tsla_non-sentiment_2024102709_predicted_data.csv\n",
      "\n",
      "Results saved to test_result_5/tsla_non-sentiment_2024102709/tsla_non-sentiment_2024102709_eval.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from datetime import datetime\n",
    "from core.data_processor import DataLoader\n",
    "from core.LSTM_modified_model import Model\n",
    "\n",
    "# 生成带有当前时间的文件夹名\n",
    "current_time = datetime.now().strftime(\"%Y%m%d%H\")\n",
    "\n",
    "\n",
    "def output_results_and_errors_multiple(\n",
    "    predicted_data,\n",
    "    true_data,\n",
    "    true_data_base,\n",
    "    prediction_len,\n",
    "    file_name,\n",
    "    sentiment_type,\n",
    "    num_csvs,\n",
    "):\n",
    "    ### 输出预测和真实值\n",
    "    # 创建一个空的DataFrame\n",
    "    save_df = pd.DataFrame()\n",
    "\n",
    "    # 将真实值添加到DataFrame中\n",
    "    save_df[\"True_Data\"] = true_data.reshape(-1)\n",
    "    save_df[\"Base\"] = true_data_base.reshape(-1)\n",
    "\n",
    "    # 转化回原scale\n",
    "    save_df[\"True_Data_origin\"] = (save_df[\"True_Data\"] + 1) * save_df[\"Base\"]\n",
    "\n",
    "    # 将所有预测数据拼接在一起\n",
    "    if predicted_data:\n",
    "        # 使用列表推导式将数组拼接\n",
    "        all_predicted_data = np.concatenate([p for p in predicted_data])\n",
    "    else:\n",
    "        # 如果 predicted_data 为空，则赋值为一个空数组或者根据你的需求进行处理\n",
    "        all_predicted_data = predicted_data\n",
    "\n",
    "    file_name = file_name.split(\".\")[0]\n",
    "    sentiment_type = str(sentiment_type)\n",
    "\n",
    "    # 将拼接后的预测数据添加到DataFrame中\n",
    "    save_df[\"Predicted_Data\"] = pd.Series(all_predicted_data)\n",
    "\n",
    "    # 转化回原scale\n",
    "    save_df[\"Predicted_Data_origin\"] = (save_df[\"Predicted_Data\"] + 1) * save_df[\"Base\"]\n",
    "\n",
    "    # 如果预测值的长度不同，则填充NaN\n",
    "    save_df = save_df.fillna(np.nan)\n",
    "    result_folder = f\"test_result_{num_csvs}\"\n",
    "    save_file_path = os.path.join(\n",
    "        result_folder,\n",
    "        f\"{file_name}_{sentiment_type}_{current_time}\",\n",
    "        f\"{file_name}_{sentiment_type}_{current_time}_predicted_data.csv\",\n",
    "    )\n",
    "    # 保存DataFrame到CSV文件\n",
    "    # 创建目录（如果不存在）\n",
    "    os.makedirs(\n",
    "        os.path.join(result_folder, f\"{file_name}_{sentiment_type}_{current_time}\"),\n",
    "        exist_ok=True,\n",
    "    )\n",
    "\n",
    "    save_df.to_csv(save_file_path, index=False)\n",
    "    print(f\"Data saved to {save_file_path}\")\n",
    "    ### 输出eval\n",
    "    # 截断数据以确保长度一致\n",
    "    min_length = min(len(save_df[\"Predicted_Data\"]), len(save_df[\"True_Data\"]))\n",
    "    predicted_data = save_df[\"Predicted_Data\"][:min_length]\n",
    "    true_data = save_df[\"True_Data\"][:min_length]\n",
    "\n",
    "    # 计算 MAE, MSE, R²\n",
    "    mae = mean_absolute_error(true_data, predicted_data)\n",
    "    mse = mean_squared_error(true_data, predicted_data)\n",
    "    r2 = r2_score(true_data, predicted_data)\n",
    "\n",
    "    print(\"MAE:\", mae)\n",
    "    print(\"MSE:\", mse)\n",
    "    print(\"R²:\", r2)\n",
    "    results_df = pd.DataFrame({\"MAE\": [mae], \"MSE\": [mse], \"R2\": [r2]})\n",
    "\n",
    "    eval_file_path = os.path.join(\n",
    "        result_folder,\n",
    "        f\"{file_name}_{sentiment_type}_{current_time}\",\n",
    "        f\"{file_name}_{sentiment_type}_{current_time}_eval.csv\",\n",
    "    )\n",
    "\n",
    "    # 保存结果到CSV文件\n",
    "    results_df.to_csv(eval_file_path, index=False)\n",
    "    print(f\"\\nResults saved to {eval_file_path}\")\n",
    "\n",
    "\n",
    "# Main Function\n",
    "def main(configs, data_filename, sentiment_type, flag_pred, model_name, num_csvs):\n",
    "    print(\n",
    "        f\"flag_pred: {flag_pred}, sentiment_type: {sentiment_type}, data_filename: {data_filename}\"\n",
    "    )\n",
    "    symbol_name = name.split(\".\")[0]\n",
    "    if not os.path.exists(configs[\"model\"][\"save_dir\"]):\n",
    "        os.makedirs(configs[\"model\"][\"save_dir\"])\n",
    "\n",
    "    data = DataLoader(\n",
    "        os.path.join(\"data\", data_filename),\n",
    "        configs[\"data\"][\"train_test_split\"],\n",
    "        configs[\"data\"][\"columns\"],\n",
    "        configs[\"data\"][\"columns_to_normalise\"],\n",
    "        configs[\"data\"][\"prediction_length\"],\n",
    "    )\n",
    "\n",
    "    model = Model()\n",
    "    model_path = f\"saved_models/{model_name}_{sentiment_type}_{num_csvs}.keras\"\n",
    "    if os.path.exists(model_path):\n",
    "        model.load_model(model_path)\n",
    "    else:\n",
    "        model.build_model(configs)\n",
    "\n",
    "    x, y = data.get_train_data(\n",
    "        seq_len=configs[\"data\"][\"sequence_length\"],\n",
    "        normalise=configs[\"data\"][\"normalise\"],\n",
    "    )\n",
    "    print(\"X:\", x.shape)\n",
    "    # print(x[0])\n",
    "    print(\"Y:\", y.shape)\n",
    "    # print(y)\n",
    "    \"\"\"\n",
    "\t# in-memory training\n",
    "\tmodel.train(\n",
    "\t\tx,\n",
    "\t\ty,\n",
    "\t\tepochs = configs['training']['epochs'],\n",
    "\t\tbatch_size = configs['training']['batch_size'],\n",
    "\t\tsave_dir = configs['model']['save_dir']\n",
    "\t)\n",
    "\t\"\"\"\n",
    "    # out-of memory generative training\n",
    "    steps_per_epoch = math.ceil(\n",
    "        (data.len_train - configs[\"data\"][\"sequence_length\"])\n",
    "        / configs[\"training\"][\"batch_size\"]\n",
    "    )\n",
    "    model.train_generator(\n",
    "        data_gen=data.generate_train_batch(\n",
    "            seq_len=configs[\"data\"][\"sequence_length\"],\n",
    "            batch_size=configs[\"training\"][\"batch_size\"],\n",
    "            normalise=configs[\"data\"][\"normalise\"],\n",
    "        ),\n",
    "        epochs=configs[\"training\"][\"epochs\"],\n",
    "        batch_size=configs[\"training\"][\"batch_size\"],\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        save_dir=configs[\"model\"][\"save_dir\"],\n",
    "        sentiment_type=sentiment_type,\n",
    "        model_name=model_name,\n",
    "        num_csvs=num_csvs,\n",
    "    )\n",
    "    if flag_pred:\n",
    "        if symbol_name in pred_names:\n",
    "            print(\"-----Predicting-----\")\n",
    "            x_test, y_test, y_base = data.get_test_data(\n",
    "                seq_len=configs[\"data\"][\"sequence_length\"],\n",
    "                normalise=configs[\"data\"][\"normalise\"],\n",
    "                cols_to_norm=configs[\"data\"][\"columns_to_normalise\"],\n",
    "            )\n",
    "            print(\"test data:\")\n",
    "            print(\"X:\", x_test.shape)\n",
    "            print(\"Y:\", y_test.shape)\n",
    "            predictions = model.predict_sequences_multiple_modified(\n",
    "                x_test,\n",
    "                configs[\"data\"][\"sequence_length\"],\n",
    "                configs[\"data\"][\"prediction_length\"],\n",
    "            )\n",
    "\n",
    "            output_results_and_errors_multiple(\n",
    "                predictions,\n",
    "                y_test,\n",
    "                y_base,\n",
    "                configs[\"data\"][\"prediction_length\"],\n",
    "                symbol_name,\n",
    "                sentiment_type,\n",
    "                num_csvs,\n",
    "            )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model_name = \"LSTM\"\n",
    "    sentiment_types = [\"sentiment\", \"non-sentiment\"]  # \"sentiment\", \"non-sentiment\"\n",
    "\n",
    "    # Test csvs = 5\n",
    "    names_5 = [\"aa.csv\", \"aapl.csv\", \"amzn.csv\", \"msft.csv\", \"tsla.csv\"]\n",
    "    names_25 = []\n",
    "    names_50 = []\n",
    "    all_names = [names_5]\n",
    "    # all_names = [names_5, names_25, names_50]\n",
    "    pred_names = [\"aa\", \"aapl\", \"amzn\", \"msft\", \"tsla\"]\n",
    "    for names in all_names:\n",
    "        num_stocks = len(names)\n",
    "        # num_stocks = 5\n",
    "        # num_stocks = 25\n",
    "        # num_stocks = 50\n",
    "        # For the first and second runs, only model training was performed\n",
    "        # In the third run, it will train and make predictions\n",
    "        for i in range(3):\n",
    "            if_pred = False\n",
    "            if i == 0 or i == 1:\n",
    "                continue\n",
    "            if i == 2:\n",
    "                if_pred = True\n",
    "            for sentiment_type in sentiment_types:\n",
    "                for name in names:\n",
    "                    configs = json.load(open(sentiment_type + \"-config.json\", \"r\"))\n",
    "                    print(f\"#{i}\")\n",
    "                    main(configs, name, sentiment_type, if_pred, model_name, num_stocks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define global constants for sentiment training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_TEST_SPLIT = 0.85\n",
    "COLUMNS = [\"Close\", \"Volume\", \"Normalized_sentiment\"]\n",
    "COLUMNS_TO_NORMALISE = [0, 1]\n",
    "PREDICTION_LENGTH = 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Sentiment Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "\n",
    "sequential_model = keras.Sequential([keras.layers.Dense(2)])\n",
    "sequential_model.save(\"saved_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingest Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read combined data from CSV files to Spark dataframe\n",
    "df_data = spark.read.csv(FILE_PATH_COMBINED, header=True, schema=COMBINED_SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify\n",
    "print(f\"Row count for df_data: {df_data.count()}\")\n",
    "df_data.show(5, truncate=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
